{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ConvNet model in tensorflow\n",
    "Construction of a simple convolutional network with Tensorflow to demonstrate the basic functions of the framework.\n",
    "The MNIST dataset is used for network testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Training set=====\n",
      "images: (55000, 784)\n",
      "labels: (55000, 10)\n",
      "\n",
      "=====Validation set=====\n",
      "images: (5000, 784)\n",
      "labels: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_valid = mnist.validation.images\n",
    "Y_valid = mnist.validation.labels\n",
    "\n",
    "print('=====Training set=====')\n",
    "print('images:', X_train.shape)\n",
    "print('labels:', Y_train.shape)\n",
    "print('\\n=====Validation set=====')\n",
    "print('images:', X_valid.shape)\n",
    "print('labels:', Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a convolutional network, so it is more convenient to leave the images in their original format, in the case of MNIST, 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Training set=====\n",
      "images: (55000, 28, 28, 1)\n",
      "labels: (55000, 10)\n",
      "\n",
      "=====Validation set=====\n",
      "images: (5000, 28, 28, 1)\n",
      "labels: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_channels = 1\n",
    "\n",
    "def reformat(data):\n",
    "    return np.reshape(data, (-1, image_size, image_size, num_channels))\n",
    "\n",
    "X_train = reformat(train_dataset)\n",
    "X_valid = reformat(valid_dataset)\n",
    "\n",
    "print('=====Training set=====')\n",
    "print('images:', X_train.shape)\n",
    "print('labels:', Y_train.shape)\n",
    "print('\\n=====Validation set=====')\n",
    "print('images:', X_valid.shape)\n",
    "print('labels:', Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Display some MNIST images. Run multiple times for different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52191\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADqpJREFUeJzt3X+sVPWZx/HPo5TEQImwXAkKeuuP1NyQSJORQFYNyFKt\nqcHGaCCxwaQujVbSJpXUYFT+ITGrlBAVlK6kdNMV1qCCBluVGK7opmEkLGjdXVEvAYJwkcZajbDK\ns3/cQ3PFO99zmTkzZ+593q/k5s6cZ86ch4EPZ+Z8z5yvubsAxHNW2Q0AKAfhB4Ii/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8Q1IhWbmz8+PHe2dnZyk0CofT09Ojo0aM2mMc2FH4zu17SSklnS/pXd38o\n9fjOzk5Vq9VGNgkgoVKpDPqxdb/tN7OzJT0u6QeSuiTNN7Ouep8PQGs18pl/mqS97v6Bu5+QtF7S\n3GLaAtBsjYT/Akn7+90/kC37GjNbaGZVM6v29vY2sDkARWr60X53X+PuFXevdHR0NHtzAAapkfAf\nlDS53/1J2TIAQ0Aj4d8h6TIz+46ZjZQ0T9LmYtoC0Gx1D/W5+5dmdrekP6pvqG+tu79TWGcAmqqh\ncX533yJpS0G9AGghTu8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ER\nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiWTtEN9PfZZ58l6x9++GGyPmXKlCLbCYc9\nPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1dA4v5n1SPpU0leSvnT3ShFNYfi4//77a9ZefPHF5Lq7\nd+9O1ufOnZusL168uGZtxowZyXUjKOIkn1nufrSA5wHQQrztB4JqNPwu6VUze8vMFhbREIDWaPRt\n/1XuftDMzpP0ipn9t7t3939A9p/CQkm68MILG9wcgKI0tOd394PZ7yOSnpM0bYDHrHH3irtXOjo6\nGtkcgALVHX4zG2Vm3z51W9L3Jb1dVGMAmquRt/0TJD1nZqee59/d/Q+FdAWg6eoOv7t/IOmKAntB\nE3zyySfJ+vHjx5P1ZcuWJesbNmxI1j/++OOatZMnTybXzfP8888n6y+99FLN2pIlS5Lrps5PGC4Y\n6gOCIvxAUIQfCIrwA0ERfiAowg8ExaW7h4FnnnmmZu2ee+5JrnvgwIFk3d2T9ew8j1LMnDmz7nWX\nL1+erM+ZMydZnz59et3bbhfs+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb5h4EHHnigZi1vHL/Z\nzjnnnJq1++67L7lu3qW5u7q66upJkmbPnp2sP/zww8n6xo0b6952u2DPDwRF+IGgCD8QFOEHgiL8\nQFCEHwiK8ANBMc4/DMyaNatmbcSIxv6K8y5xPX/+/IaevyxXX311st7d3Z2sDwfs+YGgCD8QFOEH\ngiL8QFCEHwiK8ANBEX4gqNxBYDNbK+mHko64+5Rs2ThJGyR1SuqRdKu7/6V5bSJl1apVZbcw5Gza\ntClZHzt2bIs6Kc9g9vy/lXT9acvulbTV3S+TtDW7D2AIyQ2/u3dLOnba4rmS1mW310m6qeC+ADRZ\nvZ/5J7j7oez2R5ImFNQPgBZp+ICf903mVnNCNzNbaGZVM6v29vY2ujkABak3/IfNbKIkZb+P1Hqg\nu69x94q7Vzo6OurcHICi1Rv+zZIWZLcXSEofOgXQdnLDb2ZPS/pPSd81swNm9hNJD0maY2bvSfqn\n7D6AISR3nN/da31hO33hc6CNjRs3LlnvO5Q1vHGGHxAU4QeCIvxAUIQfCIrwA0ERfiAoLt2NYWvp\n0qU1a2+++Wbd6w4X7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+Vtgz549yfq2bduS9bPOSv8f\nfeWVV9ZVG+qOHTv9urJft379+pq1GTNmJNe988476+ppKGHPDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBhRnn/+KLL5L1Rx55JFl/4YUXatZ27NhRV0+n5F0m2swaev6UefPmJetLlixp6Pkvv/zymrUR\nIxr753f33Xcn68ePH69Zy/u+/pgxY+ppaUhhzw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQeUOtJrZ\nWkk/lHTE3adky5ZK+mdJvdnDlrj7lmY1WYSXX345WX/wwQfrfu5Gx+EvvfTSZP39999v6PlTNmzY\nkKynvhMv5f/ZZ8+uPZN73jkE1Wo1Wc/r7bXXXqtZu+aaa5LrRjCYPf9vJV0/wPIV7j41+2nr4AP4\nptzwu3u3pPQlUwAMOY185l9kZrvNbK2ZjS2sIwAtUW/4V0u6WNJUSYckLa/1QDNbaGZVM6v29vbW\nehiAFqsr/O5+2N2/cveTkn4jaVrisWvcveLulY6Ojnr7BFCwusJvZhP73f2RpLeLaQdAqwxmqO9p\nSTMljTezA5IelDTTzKZKckk9kn7axB4BNEFu+N19/gCLn2pCL02V9731PKNGjapZyxunzxuPPv/8\n8xta/7rrrqtZy7u2/aZNm5L1vPWffPLJZH3r1q01a6+//npy3ZMnTybr5513XrJ+0UUXJevRcYYf\nEBThB4Ii/EBQhB8IivADQRF+ICgu3Z3J+2pq6ivB06dPr6unwbrjjjvqXnfy5MnJ+hVXXJGsP/vs\ns8l63jBk6pTuEydOJNfNk7o0tyR9/vnnDT3/cMeeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCCjPO\nn/eV3rxLWK9evbpmbefOncl1p0yZkqw38zLSBw8eTNaXLVuWrD/xxBPJeiOXLU99FVmSLrnkkmT9\n8ccfT9Yfe+yxmrVVq1Yl142APT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBGXu3rKNVSoVz5t2uSyz\nZs1K1rdt29a0bef9HeSNpU+bVnPCpNxLb+/duzdZz+uts7MzWV+8eHHN2l133ZVcN0/en23p0qU1\na/v370+uu2LFimQ9789dlkqlomq1OqiTL9jzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQueP8ZjZZ\n0u8kTZDkkta4+0ozGydpg6ROST2SbnX3v6Seq53H+Xft2pWsr1y5smZt3759yXXzzhFodJy/EXnT\niy9atChZv+2225L1c88994x7Kkrq7/Taa69Nrjtp0qRkffv27cn6mDFjkvVmKXqc/0tJv3T3LknT\nJf3MzLok3Stpq7tfJmlrdh/AEJEbfnc/5O47s9ufSnpX0gWS5kpalz1snaSbmtUkgOKd0Wd+M+uU\n9D1Jf5I0wd0PZaWP1PexAMAQMejwm9loSRsl/cLd/9q/5n0fWgf84GpmC82sambV1LxtAFprUOE3\ns2+pL/i/d/dTMzceNrOJWX2ipCMDrevua9y94u6Vjo6OInoGUIDc8FvfoeanJL3r7r/uV9osaUF2\ne4GkTcW3B6BZBjPUd5Wk1yXtkXQyW7xEfZ/7/0PShZL2qW+oL/kdy3Ye6mtE3lTTb7zxRrLe3d2d\nrOcN9aUuDZ73tde8S5qPHj06WR+qbrzxxmR9y5YtyXre15EfffTRM+6pCGcy1Jd73X533y6p1pPN\nPpPGALQPzvADgiL8QFCEHwiK8ANBEX4gKMIPBBVmiu5mGjlyZLKed1nwvDqKd/PNNyfreVOb503x\nXdY4/5lgzw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOj5Buv/32ZP2WW25J1vMu1z4UsOcHgiL8\nQFCEHwiK8ANBEX4gKMIPBEX4gaAY5wcGMGrUqGS9q6urRZ00D3t+ICjCDwRF+IGgCD8QFOEHgiL8\nQFCEHwgqN/xmNtnMXjOzP5vZO2b282z5UjM7aGa7sp8bmt8ugKIM5iSfLyX90t13mtm3Jb1lZq9k\ntRXu/kjz2gPQLLnhd/dDkg5ltz81s3clXdDsxgA01xl95jezTknfk/SnbNEiM9ttZmvNbGyNdRaa\nWdXMqr29vQ01C6A4gw6/mY2WtFHSL9z9r5JWS7pY0lT1vTNYPtB67r7G3SvuXuno6CigZQBFGFT4\nzexb6gv+7939WUly98Pu/pW7n5T0G0nTmtcmgKIN5mi/SXpK0rvu/ut+yyf2e9iPJL1dfHsAmmUw\nR/v/UdKPJe0xs13ZsiWS5pvZVEkuqUfST5vSIYCmGMzR/u2SbIDSluLbAdAqnOEHBEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iyty9dRsz65W0r9+i8ZKOtqyB\nM9OuvbVrXxK91avI3i5y90FdL6+l4f/Gxs2q7l4prYGEdu2tXfuS6K1eZfXG234gKMIPBFV2+NeU\nvP2Udu2tXfuS6K1epfRW6md+AOUpe88PoCSlhN/Mrjez/zGzvWZ2bxk91GJmPWa2J5t5uFpyL2vN\n7IiZvd1v2Tgze8XM3st+DzhNWkm9tcXMzYmZpUt97dptxuuWv+03s7Ml/a+kOZIOSNohab67/7ml\njdRgZj2SKu5e+piwmV0j6W+SfufuU7Jl/yLpmLs/lP3HOdbdf9UmvS2V9LeyZ27OJpSZ2H9maUk3\nSbpdJb52ib5uVQmvWxl7/mmS9rr7B+5+QtJ6SXNL6KPtuXu3pGOnLZ4raV12e536/vG0XI3e2oK7\nH3L3ndntTyWdmlm61Ncu0Vcpygj/BZL297t/QO015bdLetXM3jKzhWU3M4AJ2bTpkvSRpAllNjOA\n3JmbW+m0maXb5rWrZ8bronHA75uucvepkn4g6WfZ29u25H2f2dppuGZQMze3ygAzS/9dma9dvTNe\nF62M8B+UNLnf/UnZsrbg7gez30ckPaf2m3348KlJUrPfR0ru5+/aaebmgWaWVhu8du0043UZ4d8h\n6TIz+46ZjZQ0T9LmEvr4BjMblR2IkZmNkvR9td/sw5slLchuL5C0qcRevqZdZm6uNbO0Sn7t2m7G\na3dv+Y+kG9R3xP99SfeV0UONvi6W9F/Zzztl9ybpafW9Dfw/9R0b+Ymkf5C0VdJ7kl6VNK6Nevs3\nSXsk7VZf0CaW1NtV6ntLv1vSruznhrJfu0RfpbxunOEHBMUBPyAowg8ERfiBoAg/EBThB4Ii/EBQ\nhB8IivADQf0/xFilzg4sfs0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa4c259950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "index = randint(0, X_train.shape[0] - 1)\n",
    "print(index)\n",
    "plt.imshow(X_train[index].reshape(28, 28), cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "filter_size = 5\n",
    "depth1 = 6\n",
    "depth2 = 16\n",
    "fc_input_size = 400 # tentar calcular com o shape quando tiver tempo\n",
    "fc1_size = 120\n",
    "fc2_size = 84\n",
    "num_labels = 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    # inputs\n",
    "    data = tf.placeholder(tf.float32, shape=(None, image_size, image_size, num_channels))\n",
    "    labels = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "    \n",
    "    # convolutional layers learnable parameters\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([filter_size, filter_size, num_channels, depth1], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth1]))\n",
    "    \n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([filter_size, filter_size, depth1, depth2], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.zeros([depth2]))\n",
    "    \n",
    "    # feedforward layers learnable parameters\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([fc_input_size, fc1_size], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.zeros([fc1_size]))\n",
    "    \n",
    "    layer4_weights = tf.Variable(tf.truncated_normal([fc1_size, fc2_size], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.zeros([fc2_size]))\n",
    "    \n",
    "    layer5_weights = tf.Variable(tf.truncated_normal([fc2_size, num_labels], stddev=0.1))\n",
    "    layer5_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # build the model\n",
    "    def model(data):\n",
    "        conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME'), layer1_biases))\n",
    "        pool1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "        conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(pool1, layer2_weights, [1, 1, 1, 1], padding='VALID'), layer2_biases))\n",
    "        pool2 = tf.nn.max_pool(conv2, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "        \n",
    "        shape = pool2.get_shape().as_list()\n",
    "        reshaped = tf.reshape(pool2, [-1, 400])\n",
    "        fc1 = tf.nn.relu(tf.add(tf.matmul(reshaped, layer3_weights), layer3_biases))\n",
    "        \n",
    "        fc2 = tf.nn.relu(tf.add(tf.matmul(fc1, layer4_weights), layer4_biases))\n",
    "        \n",
    "        return tf.add(tf.matmul(fc2, layer5_weights), layer5_biases)\n",
    "    \n",
    "    \n",
    "    # optimizing\n",
    "    logits = model(data)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    optmizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    # prediction and accuracy\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "    model_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "loss: 0.103588\n",
      "validation accuracy: 0.9642\n",
      "--- 0.295673596859 minutes ---\n",
      "\n",
      "epoch 2\n",
      "loss: 0.0538965\n",
      "validation accuracy: 0.9816\n",
      "--- 0.294170868397 minutes ---\n",
      "\n",
      "epoch 3\n",
      "loss: 0.0721029\n",
      "validation accuracy: 0.9824\n",
      "--- 0.289755634467 minutes ---\n",
      "\n",
      "epoch 4\n",
      "loss: 0.0239399\n",
      "validation accuracy: 0.9836\n",
      "--- 0.298274699847 minutes ---\n",
      "\n",
      "epoch 5\n",
      "loss: 0.010534\n",
      "validation accuracy: 0.9872\n",
      "--- 0.295529699326 minutes ---\n",
      "\n",
      "epoch 6\n",
      "loss: 0.0214702\n",
      "validation accuracy: 0.9874\n",
      "--- 0.292865184943 minutes ---\n",
      "\n",
      "epoch 7\n",
      "loss: 0.0293376\n",
      "validation accuracy: 0.9886\n",
      "--- 0.293183398247 minutes ---\n",
      "\n",
      "epoch 8\n",
      "loss: 0.0651265\n",
      "validation accuracy: 0.9848\n",
      "--- 0.294742063681 minutes ---\n",
      "\n",
      "epoch 9\n",
      "loss: 0.0224603\n",
      "validation accuracy: 0.99\n",
      "--- 0.290889648596 minutes ---\n",
      "\n",
      "epoch 10\n",
      "loss: 0.0161203\n",
      "validation accuracy: 0.98\n",
      "--- 0.294297949473 minutes ---\n",
      "\n",
      "epoch 11\n",
      "loss: 0.00339015\n",
      "validation accuracy: 0.9878\n",
      "--- 0.296473983924 minutes ---\n",
      "\n",
      "epoch 12\n",
      "loss: 0.00108593\n",
      "validation accuracy: 0.9894\n",
      "--- 0.291473066807 minutes ---\n",
      "\n",
      "epoch 13\n",
      "loss: 0.0220473\n",
      "validation accuracy: 0.9886\n",
      "--- 0.302804100513 minutes ---\n",
      "\n",
      "epoch 14\n",
      "loss: 0.00442631\n",
      "validation accuracy: 0.988\n",
      "--- 0.316272266706 minutes ---\n",
      "\n",
      "epoch 15\n",
      "loss: 0.00586475\n",
      "validation accuracy: 0.9912\n",
      "--- 0.302751886845 minutes ---\n",
      "\n",
      "epoch 16\n",
      "loss: 0.000981211\n",
      "validation accuracy: 0.99\n",
      "--- 0.30020468235 minutes ---\n",
      "\n",
      "epoch 17\n",
      "loss: 0.00106585\n",
      "validation accuracy: 0.9904\n",
      "--- 0.300549419721 minutes ---\n",
      "\n",
      "epoch 18\n",
      "loss: 0.000232383\n",
      "validation accuracy: 0.9924\n",
      "--- 0.300281433264 minutes ---\n",
      "\n",
      "epoch 19\n",
      "loss: 0.000934773\n",
      "validation accuracy: 0.9908\n",
      "--- 0.300144533316 minutes ---\n",
      "\n",
      "epoch 20\n",
      "loss: 0.00666693\n",
      "validation accuracy: 0.9908\n",
      "--- 0.300003782908 minutes ---\n",
      "\n",
      "test accuracy: 0.9886\n",
      "--- 0.300955518087 minutes ---\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # if taking too long to run, changing this to 10 should make little to no difference\n",
    "num_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch', epoch + 1)\n",
    "        start_time = time.time()\n",
    "        for batch in range(num_batches):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            batch_x = reformat(batch_x)\n",
    "            x_valid = reformat(mnist.validation.images)\n",
    "            y_valid = mnist.validation.labels\n",
    "            _, l = session.run([optmizer, loss], feed_dict={data:batch_x, labels:batch_y})\n",
    "#             l = session.run(loss, feed_dict={data:batch_x, labels:batch_y})\n",
    "            valid_acc = session.run(model_accuracy, feed_dict={data:x_valid, labels:y_valid})\n",
    "        print('loss:', l)\n",
    "        print('validation accuracy:', valid_acc)\n",
    "        print('--- %s minutes ---' % ((time.time() - start_time)/60))\n",
    "        print()\n",
    "    \n",
    "    test_data = reformat(mnist.test.images)\n",
    "    test_acc = session.run(model_accuracy, feed_dict={data:test_data, labels:mnist.test.labels})\n",
    "    print('test accuracy:', test_acc)\n",
    "    print('--- %s minutes ---' % ((time.time() - start_time)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
